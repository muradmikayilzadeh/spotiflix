{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9127f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import requests\n",
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.nn import init\n",
    "import pandas as pd\n",
    "from pyAudioAnalysis import audioBasicIO as io\n",
    "from os import path\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "164cd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtil():\n",
    "  # ----------------------------\n",
    "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    return (sig, sr)\n",
    "\n",
    "  @staticmethod\n",
    "  def rechannel(aud, new_channel):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sig.shape[0] == new_channel):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    if (new_channel == 1):\n",
    "      # Convert from stereo to mono by selecting only the first channel\n",
    "      resig = sig[:1, :]\n",
    "    else:\n",
    "      # Convert from mono to stereo by duplicating the first channel\n",
    "      resig = torch.cat([sig, sig])\n",
    "\n",
    "    return ((resig, sr))\n",
    "\n",
    "  @staticmethod\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sr == newsr):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    # Resample first channel\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      # Resample the second channel and merge both channels\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "\n",
    "  @staticmethod\n",
    "  def pad_trunc(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "      # Truncate the signal to the given length\n",
    "      sig = sig[:,:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "      # Length of padding to add at the beginning and end of the signal\n",
    "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "      pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "      # Pad with 0s\n",
    "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "      \n",
    "    return (sig, sr)\n",
    "\n",
    "  @staticmethod\n",
    "  def time_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    _, sig_len = sig.shape\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return (sig.roll(shift_amt), sr)\n",
    "\n",
    "  @staticmethod\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "    spec = torchaudio.transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "    # Convert to decibels\n",
    "    spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "  @staticmethod\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = torchaudio.transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = torchaudio.transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee104333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "        \n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.lin = nn.Linear(in_features=64, out_features=7)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.lin(x)\n",
    "#         x = self.lin2(x)\n",
    "#         x = self.lin3(x)\n",
    "        x = self.sig(x)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bce83ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelToPositivityModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelToPositivityModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "    \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.fchehe1 = nn.Linear(7,1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fchehe1(x)\n",
    "#         x = self.fchehe2(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu2(x)\n",
    "\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.relu3(x)\n",
    "\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9413ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LabelToClusterModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelToClusterModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "#         self.relu1 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "#         self.relu2 = nn.LeakyReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "#         self.relu3 = nn.LeakyReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(128, 500)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.zeros_(self.fc3.bias)\n",
    "        nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        nn.init.zeros_(self.fc4.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "#         x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "#         x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "#         x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "#         x = self.softmax(x)\n",
    "#         self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bd8a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_id(song_name, artist_name, token):\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    query_params = {\n",
    "        \"q\": f\"{song_name} {artist_name}\",\n",
    "        \"type\": \"track\"\n",
    "    }\n",
    "    print(song_name)\n",
    "    response = requests.get(\"https://api.spotify.com/v1/search\", headers=headers, params=query_params)\n",
    "    try:\n",
    "\n",
    "        if response.json()[\"tracks\"][\"items\"] is not None:\n",
    "            results = response.json()[\"tracks\"][\"items\"]\n",
    "            output = []\n",
    "            return results[0][\"id\"]\n",
    "\n",
    "    except KeyError:\n",
    "        print(\"Spotify error\")\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5245cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_spotify_labels(id, token):\n",
    "    labels = []\n",
    "    r=requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + id,\n",
    "                   headers={\"Accept\": \"application/json\",\n",
    "                            \"Content-Type\": \"application/json\",\n",
    "                            \"Authorization\": \"Bearer \" + token})\n",
    "    res = r.json()[\"audio_features\"][0]\n",
    "    labels.append(res[\"acousticness\"] * 100)\n",
    "    labels.append(res[\"danceability\"] * 100)\n",
    "    labels.append(res[\"energy\"] * 100)\n",
    "    labels.append(res[\"instrumentalness\"] * 100)\n",
    "    labels.append(res[\"liveness\"] * 100)\n",
    "    labels.append(res[\"speechiness\"] * 100)\n",
    "    labels.append(res[\"valence\"] * 100)\n",
    "    \n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "930596f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongLabels(song_name, artist_name, token):\n",
    "    id = get_spotify_id(song_name, artist_name, token)\n",
    "    print(id)\n",
    "    return get_spotify_labels(id, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "776d8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendMoviesFromLabels(labels, pathToModel, movieMatches, movies):\n",
    "    \n",
    "    model = torch.load(pathToModel)\n",
    "    \n",
    "    predictedCluster = \"asd\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputt = (torch.Tensor(labels)).unsqueeze(0)\n",
    "\n",
    "        predictedCluster = model(inputt)\n",
    "\n",
    "        _, predictedCluster = torch.max(predictedCluster.data, 1)\n",
    "        predictedCluster = predictedCluster.item()\n",
    "\n",
    "\n",
    "    movieCluster = movieMatches[movieMatches[\"spotify_cluster_id\"] == predictedCluster][\"movie_cluster_id\"].item()\n",
    "\n",
    "    matches = movies[movies[\"cluster_id\"] == movieCluster]\n",
    "    \n",
    "    final = []\n",
    "    for movie in matches[\"movie\"]:\n",
    "        if movie not in final:\n",
    "            final.append(movie)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44e444d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recMovieFromSpoti(pathToModel, song_name, artist_name, token, movieMatches, movies):\n",
    "    songLabels = getSongLabels(song_name, artist_name, token)\n",
    "    print(\"labels: \", songLabels)\n",
    "    recs = recommendMoviesFromLabels(songLabels,pathToModel,movieMatches,movies )\n",
    "    for movie in recs:\n",
    "        print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0c38a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpectrogram(path):\n",
    "    duration = 20000\n",
    "    sr = 44100\n",
    "    channel = 2\n",
    "    shift_pct = 0.4\n",
    "    sound = AudioSegment.from_mp3(path)\n",
    "    sound.export(\"./testSong.wav\", format=\"wav\")\n",
    "    aud = AudioUtil.open(\"./testSong.wav\")\n",
    "\n",
    "    reaud = AudioUtil.resample(aud, sr)\n",
    "    rechan = AudioUtil.rechannel(reaud, channel)\n",
    "\n",
    "    dur_aud = AudioUtil.pad_trunc(rechan, duration)\n",
    "    shift_aud = AudioUtil.time_shift(dur_aud, shift_pct)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    \n",
    "    return aug_sgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36ab1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpotifyLabelFromWave(spectro):\n",
    "    model = MultilabelClassifier()\n",
    "    model.load_state_dict(torch.load(\"./final.pt\"))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputt = (torch.Tensor(spectro)).unsqueeze(0)\n",
    "        result = model(inputt)\n",
    "    return [i * 100 for i in result[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e070aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recMovieFromMp3(path=\"./testSong.mp3\"):\n",
    "    spectro = getSpectrogram(path)\n",
    "    labels = getSpotifyLabelFromWave(spectro)\n",
    "    recs = recommendMoviesFromLabels(labels,\"./labeltocluster.pt\" ,movieMatches,movies )\n",
    "    for movie in recs:\n",
    "        print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49a310a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecsFromPos(song_name, artist, token, path=\"./labeltopos.pt\"):\n",
    "    labels = [i/100 for i in getSongLabels(song_name, artist, token)]\n",
    "    model = torch.load(path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputt = torch.Tensor(labels).unsqueeze(0)\n",
    "        result = model(inputt)\n",
    "        \n",
    "    result = result[0].item()\n",
    "    \n",
    "    closestIndex = 0\n",
    "    closestDiff = 1000\n",
    "    for i in range(movieRatings.shape[0]):\n",
    "        diff = abs(movieRatings[\"overall_positiveness_score\"][i] - result)\n",
    "        if diff < closestDiff:\n",
    "            closestDiff = diff\n",
    "            closestIndex = i\n",
    "#     print(closestIndex)\n",
    "    if (closestIndex < 0):\n",
    "        closestIndex += 3\n",
    "    elif closestIndex > movieRatings.shape[0]-2:\n",
    "        closestIndex -= 3\n",
    "\n",
    "    recList = []\n",
    "    recList.append(movieRatings[\"filename\"][closestIndex-2])\n",
    "    recList.append(movieRatings[\"filename\"][closestIndex-1])\n",
    "    recList.append(movieRatings[\"filename\"][closestIndex])\n",
    "    recList.append(movieRatings[\"filename\"][closestIndex+1])\n",
    "    recList.append(movieRatings[\"filename\"][closestIndex+2])\n",
    "    for rec in recList:\n",
    "        print(rec)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef1bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieMatches = pd.read_csv(\"./cluters_translation_table.csv\", low_memory= False)\n",
    "movies = pd.read_csv(\"./movie_soundtracks_table.csv\", low_memory=False)\n",
    "movieRatings = pd.read_csv(\"./sentiment_analysis_results.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1237d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"BQA5v7Nzp6uUB0hqMqKc6FB9fz0jjY1quCvl7vR2zvW6Q2UNo9Ul2bY7PCWiwkloR8JgPnXkID9O2uxWmD9vaR5ECbGABk2kvk8tnuxElLOJH165EAvqoDngYqG6wg7QklvW4fqaP-2S3s6l9Jq19KTzWv37DnkiG08ScZayWDsUIYZckpY0F5reT1ouVkEInQvA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e60dbf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne me quitte pas\n",
      "6IRA4KOVbtiGiTdYoEThJN\n",
      "labels:  [82.1, 41.6, 23.599999999999998, 0.012, 18.9, 4.99, 30.2]\n",
      "Casino\n",
      "Mad Max: Fury Road\n",
      "The Terminator\n",
      "Game of Thrones\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recMovieFromSpoti(\"./labeltocluster.pt\", \"ne me quitte pas\", \"jacques brel\", token, movieMatches,movies )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf9286c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider-Man: Into the Spider-Verse\n",
      "3 Idiots\n",
      "The Hunt\n",
      "Casino\n",
      "Fargo\n",
      "Prisoners\n",
      "La Haine\n"
     ]
    }
   ],
   "source": [
    "recMovieFromMp3(\"./volare.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f8cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne me quitte pas\n",
      "6IRA4KOVbtiGiTdYoEThJN\n",
      "file_1781.txt\n",
      "file_2608.txt\n",
      "file_1819.txt\n",
      "file_2074.txt\n",
      "file_827.txt\n"
     ]
    }
   ],
   "source": [
    "getRecsFromPos(\"ne me quitte pas\", \"jacques brel\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec708a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
